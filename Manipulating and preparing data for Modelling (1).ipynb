{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating and preparing data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext(master='local[2]',\n",
    "               appName='my-spark')\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense vs Sparse Vector\n",
    "\n",
    "A vector can be represented in dense and sparse formats. A dense vector is a regular vector that has each elements printed. A sparse vector use three components to represent a vector but with less memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector, DenseVector, SparseVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.0, 0.0, 0.0, 0.0, 4.5, 0.0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv=DenseVector([1,0,0,0,4.5,0])\n",
    "dv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Vector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(6, {0: 1.0, 4: 4.5})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv=SparseVector(6,{0:1.0,4:4.5})\n",
    "sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert sparse vector to dense vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.0, 0.0, 0.0, 0.0, 4.5, 0.0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DenseVector(sv.toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert dense vector to sparse vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Rows by index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|         model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|     Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
      "| Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
      "|    Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
      "|Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars=spark.read.csv('mtcars.csv',header=True,inferSchema=True)\n",
    "mtcars.dtypes\n",
    "mtcars=mtcars.withColumnRenamed('_c0','model')\n",
    "mtcars.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Row(model='Mazda RX4', mpg=21.0, cyl=6, disp=160.0, hp=110, drat=3.9, wt=2.62, qsec=16.46, vs=0, am=1, gear=4, carb=4),\n",
       "  0),\n",
       " (Row(model='Mazda RX4 Wag', mpg=21.0, cyl=6, disp=160.0, hp=110, drat=3.9, wt=2.875, qsec=17.02, vs=0, am=1, gear=4, carb=4),\n",
       "  1),\n",
       " (Row(model='Datsun 710', mpg=22.8, cyl=4, disp=108.0, hp=93, drat=3.85, wt=2.32, qsec=18.61, vs=1, am=1, gear=4, carb=1),\n",
       "  2),\n",
       " (Row(model='Hornet 4 Drive', mpg=21.4, cyl=6, disp=258.0, hp=110, drat=3.08, wt=3.215, qsec=19.44, vs=1, am=0, gear=3, carb=1),\n",
       "  3),\n",
       " (Row(model='Hornet Sportabout', mpg=18.7, cyl=8, disp=360.0, hp=175, drat=3.15, wt=3.44, qsec=17.02, vs=0, am=0, gear=3, carb=2),\n",
       "  4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtcars.rdd.zipWithIndex().take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mazda RX4', 21.0, 6, 160.0, 110, 3.9, 2.62, 16.46, 0, 1, 4, 4, 0),\n",
       " ('Mazda RX4 Wag', 21.0, 6, 160.0, 110, 3.9, 2.875, 17.02, 0, 1, 4, 4, 1),\n",
       " ('Datsun 710', 22.8, 4, 108.0, 93, 3.85, 2.32, 18.61, 1, 1, 4, 1, 2),\n",
       " ('Hornet 4 Drive', 21.4, 6, 258.0, 110, 3.08, 3.215, 19.44, 1, 0, 3, 1, 3),\n",
       " ('Hornet Sportabout', 18.7, 8, 360.0, 175, 3.15, 3.44, 17.02, 0, 0, 3, 2, 4)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "mtcars.rdd.zipWithIndex().map(lambda x: x[0]+Row(index=x[1])).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names=mtcars.columns+['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|              model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|index|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|          Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|    0|\n",
      "|      Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|    1|\n",
      "|         Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|    2|\n",
      "|     Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|    3|\n",
      "|  Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|    4|\n",
      "|            Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|    5|\n",
      "|         Duster 360|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|    6|\n",
      "|          Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|    7|\n",
      "|           Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|    8|\n",
      "|           Merc 280|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|    9|\n",
      "|          Merc 280C|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|   10|\n",
      "|         Merc 450SE|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|   11|\n",
      "|         Merc 450SL|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|   12|\n",
      "|        Merc 450SLC|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|   13|\n",
      "| Cadillac Fleetwood|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4|   14|\n",
      "|Lincoln Continental|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4|   15|\n",
      "|  Chrysler Imperial|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|   16|\n",
      "|           Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|   17|\n",
      "|        Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|   18|\n",
      "|     Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|   19|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars.rdd.zipWithIndex().map(lambda x: x[0]+Row(index=x[1])).toDF(col_names).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|              model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|index|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|          Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|    0|\n",
      "|      Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|    1|\n",
      "|         Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|    2|\n",
      "|     Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|    3|\n",
      "|  Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|    4|\n",
      "|            Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|    5|\n",
      "|         Duster 360|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|    6|\n",
      "|          Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|    7|\n",
      "|           Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|    8|\n",
      "|           Merc 280|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|    9|\n",
      "|          Merc 280C|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|   10|\n",
      "|         Merc 450SE|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|   11|\n",
      "|         Merc 450SL|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|   12|\n",
      "|        Merc 450SLC|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|   13|\n",
      "| Cadillac Fleetwood|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4|   14|\n",
      "|Lincoln Continental|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4|   15|\n",
      "|  Chrysler Imperial|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|   16|\n",
      "|           Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|   17|\n",
      "|        Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|   18|\n",
      "|     Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|   19|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars_new=mtcars.rdd.zipWithIndex().map(lambda x: x[0]+Row(index=x[1])).toDF(col_names)\n",
    "mtcars_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|         model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|index|\n",
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "| Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|    1|\n",
      "|    Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|    2|\n",
      "|Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|    3|\n",
      "|      Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|    8|\n",
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars_new.filter(mtcars_new.index.isin(1,2,3,8)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|            model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|index|\n",
      "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|    2|\n",
      "|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|    3|\n",
      "|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|    4|\n",
      "|          Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|    5|\n",
      "|       Duster 360|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|    6|\n",
      "|        Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|    7|\n",
      "|         Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|    8|\n",
      "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars_new.filter(mtcars_new.index.between(2,8)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|              model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|index|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|            Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|    5|\n",
      "|         Duster 360|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|    6|\n",
      "|          Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|    7|\n",
      "|           Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|    8|\n",
      "|           Merc 280|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|    9|\n",
      "|          Merc 280C|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|   10|\n",
      "|         Merc 450SE|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|   11|\n",
      "|         Merc 450SL|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|   12|\n",
      "|        Merc 450SLC|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|   13|\n",
      "| Cadillac Fleetwood|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4|   14|\n",
      "|Lincoln Continental|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4|   15|\n",
      "|  Chrysler Imperial|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|   16|\n",
      "|           Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|   17|\n",
      "|        Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|   18|\n",
      "|     Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|   19|\n",
      "|      Toyota Corona|21.5|  4|120.1| 97| 3.7|2.465|20.01|  1|  0|   3|   1|   20|\n",
      "|   Dodge Challenger|15.5|  8|318.0|150|2.76| 3.52|16.87|  0|  0|   3|   2|   21|\n",
      "|        AMC Javelin|15.2|  8|304.0|150|3.15|3.435| 17.3|  0|  0|   3|   2|   22|\n",
      "|         Camaro Z28|13.3|  8|350.0|245|3.73| 3.84|15.41|  0|  0|   3|   4|   23|\n",
      "|   Pontiac Firebird|19.2|  8|400.0|175|3.08|3.845|17.05|  0|  0|   3|   2|   24|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars_new.filter(mtcars_new.index>4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|         model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|index|\n",
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "|    Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|    2|\n",
      "|     Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|    7|\n",
      "|      Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|    8|\n",
      "|      Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|   17|\n",
      "|   Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|   18|\n",
      "|Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|   19|\n",
      "| Toyota Corona|21.5|  4|120.1| 97| 3.7|2.465|20.01|  1|  0|   3|   1|   20|\n",
      "|     Fiat X1-9|27.3|  4| 79.0| 66|4.08|1.935| 18.9|  1|  1|   4|   1|   25|\n",
      "| Porsche 914-2|26.0|  4|120.3| 91|4.43| 2.14| 16.7|  0|  1|   5|   2|   26|\n",
      "|  Lotus Europa|30.4|  4| 95.1|113|3.77|1.513| 16.9|  1|  1|   5|   2|   27|\n",
      "|    Volvo 142E|21.4|  4|121.0|109|4.11| 2.78| 18.6|  1|  1|   4|   2|   31|\n",
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new=mtcars_new.filter(mtcars_new.cyl==4)\n",
    "new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column<b'model'>,\n",
       " Column<b'mpg'>,\n",
       " Column<b'cyl'>,\n",
       " Column<b'disp'>,\n",
       " Column<b'hp'>,\n",
       " Column<b'drat'>,\n",
       " Column<b'wt'>,\n",
       " Column<b'qsec'>,\n",
       " Column<b'vs'>,\n",
       " Column<b'am'>,\n",
       " Column<b'gear'>,\n",
       " Column<b'carb'>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_columns_all=[eval('mtcars.' + x) for x in mtcars.columns]\n",
    "original_columns_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "filter_column=F.when((mtcars.vs==1) & (mtcars.am==1),1).name('filter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column<b'model'>,\n",
       " Column<b'mpg'>,\n",
       " Column<b'cyl'>,\n",
       " Column<b'disp'>,\n",
       " Column<b'hp'>,\n",
       " Column<b'drat'>,\n",
       " Column<b'wt'>,\n",
       " Column<b'qsec'>,\n",
       " Column<b'vs'>,\n",
       " Column<b'am'>,\n",
       " Column<b'gear'>,\n",
       " Column<b'carb'>,\n",
       " Column<b'CASE WHEN ((vs = 1) AND (am = 1)) THEN 1 END AS `filter`'>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_columns_all + [filter_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+------+\n",
      "|              model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|filter|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+------+\n",
      "|          Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|  null|\n",
      "|      Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|  null|\n",
      "|         Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|     1|\n",
      "|     Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|  null|\n",
      "|  Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|  null|\n",
      "|            Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|  null|\n",
      "|         Duster 360|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|  null|\n",
      "|          Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|  null|\n",
      "|           Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|  null|\n",
      "|           Merc 280|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|  null|\n",
      "|          Merc 280C|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|  null|\n",
      "|         Merc 450SE|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|  null|\n",
      "|         Merc 450SL|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|  null|\n",
      "|        Merc 450SLC|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|  null|\n",
      "| Cadillac Fleetwood|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4|  null|\n",
      "|Lincoln Continental|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4|  null|\n",
      "|  Chrysler Imperial|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|  null|\n",
      "|           Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|     1|\n",
      "|        Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|     1|\n",
      "|     Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|     1|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars_filter=mtcars.select(original_columns_all + [filter_column])\n",
    "mtcars_filter.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+------+\n",
      "|         model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|filter|\n",
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+------+\n",
      "|    Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|     1|\n",
      "|      Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|     1|\n",
      "|   Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|     1|\n",
      "|Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|     1|\n",
      "|     Fiat X1-9|27.3|  4| 79.0| 66|4.08|1.935| 18.9|  1|  1|   4|   1|     1|\n",
      "|  Lotus Europa|30.4|  4| 95.1|113|3.77|1.513| 16.9|  1|  1|   5|   2|     1|\n",
      "|    Volvo 142E|21.4|  4|121.0|109|4.11| 2.78| 18.6|  1|  1|   4|   2|     1|\n",
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars_filter.filter(mtcars_filter['filter']==1).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|         model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|    Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
      "|      Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|\n",
      "|   Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|\n",
      "|Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|\n",
      "|     Fiat X1-9|27.3|  4| 79.0| 66|4.08|1.935| 18.9|  1|  1|   4|   1|\n",
      "|  Lotus Europa|30.4|  4| 95.1|113|3.77|1.513| 16.9|  1|  1|   5|   2|\n",
      "|    Volvo 142E|21.4|  4|121.0|109|4.11| 2.78| 18.6|  1|  1|   4|   2|\n",
      "+--------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars_filter.filter(mtcars_filter['filter']==1).drop('filter').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset Rows by logical condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns by names\n",
    "Selecting columns by names is very simple. Just use the `select()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "| mpg|cyl|\n",
      "+----+---+\n",
      "|21.0|  6|\n",
      "|21.0|  6|\n",
      "|22.8|  4|\n",
      "|21.4|  6|\n",
      "|18.7|  8|\n",
      "|18.1|  6|\n",
      "|14.3|  8|\n",
      "|24.4|  4|\n",
      "|22.8|  4|\n",
      "|19.2|  6|\n",
      "|17.8|  6|\n",
      "|16.4|  8|\n",
      "|17.3|  8|\n",
      "|15.2|  8|\n",
      "|10.4|  8|\n",
      "|10.4|  8|\n",
      "|14.7|  8|\n",
      "|32.4|  4|\n",
      "|30.4|  4|\n",
      "|33.9|  4|\n",
      "+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars.select('mpg','cyl').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+\n",
      "|              model| mpg|cyl|\n",
      "+-------------------+----+---+\n",
      "|          Mazda RX4|21.0|  6|\n",
      "|      Mazda RX4 Wag|21.0|  6|\n",
      "|         Datsun 710|22.8|  4|\n",
      "|     Hornet 4 Drive|21.4|  6|\n",
      "|  Hornet Sportabout|18.7|  8|\n",
      "|            Valiant|18.1|  6|\n",
      "|         Duster 360|14.3|  8|\n",
      "|          Merc 240D|24.4|  4|\n",
      "|           Merc 230|22.8|  4|\n",
      "|           Merc 280|19.2|  6|\n",
      "|          Merc 280C|17.8|  6|\n",
      "|         Merc 450SE|16.4|  8|\n",
      "|         Merc 450SL|17.3|  8|\n",
      "|        Merc 450SLC|15.2|  8|\n",
      "| Cadillac Fleetwood|10.4|  8|\n",
      "|Lincoln Continental|10.4|  8|\n",
      "|  Chrysler Imperial|14.7|  8|\n",
      "|           Fiat 128|32.4|  4|\n",
      "|        Honda Civic|30.4|  4|\n",
      "|     Toyota Corolla|33.9|  4|\n",
      "+-------------------+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars.select([eval('mtcars.'+x) for x in ['model','mpg','cyl']] ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_indices=[0,1,3]+list(range(5,9))\n",
    "column_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model', 'mpg', 'disp', 'drat', 'wt', 'qsec', 'vs']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mtcars.columns[x] for x in column_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-----+----+-----+-----+---+\n",
      "|              model| mpg| disp|drat|   wt| qsec| vs|\n",
      "+-------------------+----+-----+----+-----+-----+---+\n",
      "|          Mazda RX4|21.0|160.0| 3.9| 2.62|16.46|  0|\n",
      "|      Mazda RX4 Wag|21.0|160.0| 3.9|2.875|17.02|  0|\n",
      "|         Datsun 710|22.8|108.0|3.85| 2.32|18.61|  1|\n",
      "|     Hornet 4 Drive|21.4|258.0|3.08|3.215|19.44|  1|\n",
      "|  Hornet Sportabout|18.7|360.0|3.15| 3.44|17.02|  0|\n",
      "|            Valiant|18.1|225.0|2.76| 3.46|20.22|  1|\n",
      "|         Duster 360|14.3|360.0|3.21| 3.57|15.84|  0|\n",
      "|          Merc 240D|24.4|146.7|3.69| 3.19| 20.0|  1|\n",
      "|           Merc 230|22.8|140.8|3.92| 3.15| 22.9|  1|\n",
      "|           Merc 280|19.2|167.6|3.92| 3.44| 18.3|  1|\n",
      "|          Merc 280C|17.8|167.6|3.92| 3.44| 18.9|  1|\n",
      "|         Merc 450SE|16.4|275.8|3.07| 4.07| 17.4|  0|\n",
      "|         Merc 450SL|17.3|275.8|3.07| 3.73| 17.6|  0|\n",
      "|        Merc 450SLC|15.2|275.8|3.07| 3.78| 18.0|  0|\n",
      "| Cadillac Fleetwood|10.4|472.0|2.93| 5.25|17.98|  0|\n",
      "|Lincoln Continental|10.4|460.0| 3.0|5.424|17.82|  0|\n",
      "|  Chrysler Imperial|14.7|440.0|3.23|5.345|17.42|  0|\n",
      "|           Fiat 128|32.4| 78.7|4.08|  2.2|19.47|  1|\n",
      "|        Honda Civic|30.4| 75.7|4.93|1.615|18.52|  1|\n",
      "|     Toyota Corolla|33.9| 71.1|4.22|1.835| 19.9|  1|\n",
      "+-------------------+----+-----+----+-----+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars.select([eval('mtcars.'+x) for x in [mtcars.columns[x] for x in column_indices]]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select by columns names that match a regex pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disp', 'drat']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_col=[x for x in mtcars.columns if re.compile('^d').match(x) is not None]\n",
    "sel_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column<b'disp'>, Column<b'drat'>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[eval('mtcars.'+x) for x in sel_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| disp|drat|\n",
      "+-----+----+\n",
      "|160.0| 3.9|\n",
      "|160.0| 3.9|\n",
      "|108.0|3.85|\n",
      "|258.0|3.08|\n",
      "|360.0|3.15|\n",
      "|225.0|2.76|\n",
      "|360.0|3.21|\n",
      "|146.7|3.69|\n",
      "|140.8|3.92|\n",
      "|167.6|3.92|\n",
      "|167.6|3.92|\n",
      "|275.8|3.07|\n",
      "|275.8|3.07|\n",
      "|275.8|3.07|\n",
      "|472.0|2.93|\n",
      "|460.0| 3.0|\n",
      "|440.0|3.23|\n",
      "| 78.7|4.08|\n",
      "| 75.7|4.93|\n",
      "| 71.1|4.22|\n",
      "+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars.select([eval('mtcars.'+x) for x in sel_col]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtcars.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### udf Function\n",
    "It allows us to transfer a user defined function to a pyspark.sql.functions function which can act on columns of a DataFrame. It makes data framsformation much more flexible.\n",
    "\n",
    "Using udf() could be tricky. The key to succeed is to understand how to define the returnType parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|            model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
      "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
      "|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
      "|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
      "|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
      "|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
      "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "mtcars.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def disp_by_hp(disp,hp):\n",
    "    return(disp/hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disp_by_hp_udf=udf(disp_by_hp,returnType=FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+---------+\n",
      "|              model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|  disp/hp|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+---------+\n",
      "|          Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|1.4545455|\n",
      "|      Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|1.4545455|\n",
      "|         Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|1.1612903|\n",
      "|     Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|2.3454545|\n",
      "|  Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2| 2.057143|\n",
      "|            Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1| 2.142857|\n",
      "|         Duster 360|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|1.4693878|\n",
      "|          Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2| 2.366129|\n",
      "|           Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|1.4821053|\n",
      "|           Merc 280|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|1.3626016|\n",
      "|          Merc 280C|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|1.3626016|\n",
      "|         Merc 450SE|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|1.5322223|\n",
      "|         Merc 450SL|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|1.5322223|\n",
      "|        Merc 450SLC|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|1.5322223|\n",
      "| Cadillac Fleetwood|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4| 2.302439|\n",
      "|Lincoln Continental|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4| 2.139535|\n",
      "|  Chrysler Imperial|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|1.9130435|\n",
      "|           Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|1.1924243|\n",
      "|        Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|1.4557692|\n",
      "|     Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|1.0938462|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars.select([eval('mtcars.'+x) for x in mtcars.columns] +[disp_by_hp_udf('disp','hp').name('disp/hp')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_two_col(col1, col2):\n",
    "    return([col1, col2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array_type=ArrayType(FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_two_col_udf=udf(merge_two_col,returnType=array_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtcars.select([eval('mtcars.'+ x)for x in mtcars.columns ] +\n",
    "             [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ArrayType vs. StructType\n",
    "Both `ArrayType` and `StructType` can be used to build `returnType` for a list. The difference is: \n",
    "\n",
    "1. `ArrayType` requires all elements in the list have the same `elementType`, while `StructType` can have different `elementTypes`.\n",
    "2. `StructType` represents a `Row` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct_type_example=StructType([\n",
    "    StructField('f1',StringType()),\n",
    "    StructField('f2',FloatType())\n",
    "])\n",
    "struct_merge_two_col_udf=udf(merge_two_col,returnType=struct_type_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtcars_array_type =mtcars.select([eval('mtcars.'+ x)for x in mtcars.columns ] +\n",
    "             [merge_two_col_udf('mpg','disp').name('merged_col')])\n",
    "mtcars_struct_type =mtcars.select([eval('mtcars.'+ x)for x in mtcars.columns ] +\n",
    "             [struct_merge_two_col_udf('mpg','disp').name('merged_col')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(model='Mazda RX4', mpg=21.0, cyl=6, disp=160.0, hp=110, drat=3.9, wt=2.62, qsec=16.46, vs=0, am=1, gear=4, carb=4, merged_col=[21.0, 160.0]),\n",
       " Row(model='Mazda RX4 Wag', mpg=21.0, cyl=6, disp=160.0, hp=110, drat=3.9, wt=2.875, qsec=17.02, vs=0, am=1, gear=4, carb=4, merged_col=[21.0, 160.0])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtcars_array_type.rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(model='Mazda RX4', mpg=21.0, cyl=6, disp=160.0, hp=110, drat=3.9, wt=2.62, qsec=16.46, vs=0, am=1, gear=4, carb=4, merged_col=Row(f1='21.0', f2=160.0)),\n",
       " Row(model='Mazda RX4 Wag', mpg=21.0, cyl=6, disp=160.0, hp=110, drat=3.9, wt=2.875, qsec=17.02, vs=0, am=1, gear=4, carb=4, merged_col=Row(f1='21.0', f2=160.0))]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtcars_struct_type.rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merged_col in mtcars_struct_type is a Row object, but not in mtcars_array_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "\n",
    "\n",
    "![spark pipeline](spark-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example \n",
    "\n",
    "We are going to use pipeline to StringIndex columns x1, x2, y1, and y2. Then we OneHotEncode the resulting StringIdexed colu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+---+---+\n",
      "| x1|    x2| x3| x4| y1| y2|\n",
      "+---+------+---+---+---+---+\n",
      "|  a| apple|  1|2.4|  1|yes|\n",
      "|  a|orange|  1|2.5|  0| no|\n",
      "|  b|orange|  2|3.5|  1| no|\n",
      "|  b|orange|  2|1.4|  0|yes|\n",
      "|  b| peach|  2|2.1|  0|yes|\n",
      "|  c| peach|  4|1.5|  1|yes|\n",
      "+---+------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's create some example dataset\n",
    "import pandas as pd\n",
    "pdf = pd.DataFrame({\n",
    "        'x1': ['a','a','b','b', 'b', 'c'],\n",
    "        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n",
    "        'x3': [1, 1, 2, 2, 2, 4],\n",
    "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n",
    "        'y1': [1, 0, 1, 0, 0, 1],\n",
    "        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n",
    "    })\n",
    "df = spark.createDataFrame(pdf)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+---+---+----------+\n",
      "| x1|    x2| x3| x4| y1| y2|indexed_x1|\n",
      "+---+------+---+---+---+---+----------+\n",
      "|  a| apple|  1|2.4|  1|yes|       1.0|\n",
      "|  a|orange|  1|2.5|  0| no|       1.0|\n",
      "|  b|orange|  2|3.5|  1| no|       0.0|\n",
      "|  b|orange|  2|1.4|  0|yes|       0.0|\n",
      "|  b| peach|  2|2.1|  0|yes|       0.0|\n",
      "|  c| peach|  4|1.5|  1|yes|       2.0|\n",
      "+---+------+---+---+---+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_indexer=StringIndexer(inputCol='x1',outputCol='idx_x1')\n",
    "s_indexer_model=s_indexer.fit(df)\n",
    "df_s_indexer=s_indexer_model.transform(df)\n",
    "df_s_indexer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_44ada7f2d417ab5e2b17,\n",
       " StringIndexer_47d8bdd11531b8557a01,\n",
       " StringIndexer_4066b924acf0a7da6f4e,\n",
       " StringIndexer_40de89a317c3c8c2d666]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_stage=[StringIndexer(inputCol=c,outputCol='indexed_'+c) for c in ['x1','x2','y1','y2']]\n",
    "si_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OneHotEncoder_4ddda91c113382c968dc,\n",
       " OneHotEncoder_460d8ab672f85501f12e,\n",
       " OneHotEncoder_4f9a85f4c68bb376de4b,\n",
       " OneHotEncoder_40f19d85a85373488688]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_stage = [OneHotEncoder(inputCol='indexed_'+c,outputCol='ohe_'+c) for c in ['x1','x2','y1','y2']]\n",
    "ohe_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pyspark.ml.feature.StringIndexer,\n",
       " pyspark.ml.feature.StringIndexer,\n",
       " pyspark.ml.feature.StringIndexer,\n",
       " pyspark.ml.feature.StringIndexer,\n",
       " pyspark.ml.feature.OneHotEncoder,\n",
       " pyspark.ml.feature.OneHotEncoder,\n",
       " pyspark.ml.feature.OneHotEncoder,\n",
       " pyspark.ml.feature.OneHotEncoder]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stages=si_stage+ohe_stage\n",
    "[type(x) for x in all_stages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+---+---+----------+----------+----------+----------+-------------+-------------+-------------+-------------+\n",
      "| x1|    x2| x3| x4| y1| y2|indexed_x1|indexed_x2|indexed_y1|indexed_y2|       ohe_x1|       ohe_x2|       ohe_y1|       ohe_y2|\n",
      "+---+------+---+---+---+---+----------+----------+----------+----------+-------------+-------------+-------------+-------------+\n",
      "|  a| apple|  1|2.4|  1|yes|       1.0|       2.0|       1.0|       0.0|(2,[1],[1.0])|    (2,[],[])|    (1,[],[])|(1,[0],[1.0])|\n",
      "|  a|orange|  1|2.5|  0| no|       1.0|       0.0|       0.0|       1.0|(2,[1],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|    (1,[],[])|\n",
      "|  b|orange|  2|3.5|  1| no|       0.0|       0.0|       1.0|       1.0|(2,[0],[1.0])|(2,[0],[1.0])|    (1,[],[])|    (1,[],[])|\n",
      "|  b|orange|  2|1.4|  0|yes|       0.0|       0.0|       0.0|       0.0|(2,[0],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|  b| peach|  2|2.1|  0|yes|       0.0|       1.0|       0.0|       0.0|(2,[0],[1.0])|(2,[1],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|  c| peach|  4|1.5|  1|yes|       2.0|       1.0|       1.0|       0.0|    (2,[],[])|(2,[1],[1.0])|    (1,[],[])|(1,[0],[1.0])|\n",
      "+---+------+---+---+---+---+----------+----------+----------+----------+-------------+-------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Pipeline(stages=all_stages).fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorAssembler\n",
    "\n",
    "To fit a ML model in pyspark, we need to combine all feature columns into one single column of vectors: the **featuresCol**. The `VectorAssembler` can be used to combine multiple **`OneHotEncoder` columns** and **other continuous variable columns** into one single column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+---+---+----------+----------+----------+----------+-------------+-------------+-------------+-------------+\n",
      "| x1|    x2| x3| x4| y1| y2|indexed_x1|indexed_x2|indexed_y1|indexed_y2|       ohe_x1|       ohe_x2|       ohe_y1|       ohe_y2|\n",
      "+---+------+---+---+---+---+----------+----------+----------+----------+-------------+-------------+-------------+-------------+\n",
      "|  a| apple|  1|2.4|  1|yes|       1.0|       2.0|       1.0|       0.0|(2,[1],[1.0])|    (2,[],[])|    (1,[],[])|(1,[0],[1.0])|\n",
      "|  a|orange|  1|2.5|  0| no|       1.0|       0.0|       0.0|       1.0|(2,[1],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|    (1,[],[])|\n",
      "|  b|orange|  2|3.5|  1| no|       0.0|       0.0|       1.0|       1.0|(2,[0],[1.0])|(2,[0],[1.0])|    (1,[],[])|    (1,[],[])|\n",
      "|  b|orange|  2|1.4|  0|yes|       0.0|       0.0|       0.0|       0.0|(2,[0],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|  b| peach|  2|2.1|  0|yes|       0.0|       1.0|       0.0|       0.0|(2,[0],[1.0])|(2,[1],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|  c| peach|  4|1.5|  1|yes|       2.0|       1.0|       1.0|       0.0|    (2,[],[])|(2,[1],[1.0])|    (1,[],[])|(1,[0],[1.0])|\n",
      "+---+------+---+---+---+---+----------+----------+----------+----------+-------------+-------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "df_new=Pipeline(stages=all_stages).fit(df).transform(df)\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assembling feature columns into one single feacturesCol with VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1',\n",
       " 'x2',\n",
       " 'x3',\n",
       " 'x4',\n",
       " 'y1',\n",
       " 'y2',\n",
       " 'indexed_x1',\n",
       " 'indexed_x2',\n",
       " 'indexed_y1',\n",
       " 'indexed_y2',\n",
       " 'ohe_x1',\n",
       " 'ohe_x2',\n",
       " 'ohe_y1',\n",
       " 'ohe_y2']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+---+---+-------------+-------------+-------------+-------------+-------------------------+\n",
      "|x1 |x2    |x3 |x4 |y1 |y2 |ohe_x1       |ohe_x2       |ohe_y1       |ohe_y2       |featuresCol              |\n",
      "+---+------+---+---+---+---+-------------+-------------+-------------+-------------+-------------------------+\n",
      "|a  |apple |1  |2.4|1  |yes|(2,[1],[1.0])|(2,[],[])    |(1,[],[])    |(1,[0],[1.0])|(6,[1,5],[1.0,2.4])      |\n",
      "|a  |orange|1  |2.5|0  |no |(2,[1],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|(1,[],[])    |[0.0,1.0,1.0,0.0,1.0,2.5]|\n",
      "|b  |orange|2  |3.5|1  |no |(2,[0],[1.0])|(2,[0],[1.0])|(1,[],[])    |(1,[],[])    |[1.0,0.0,1.0,0.0,0.0,3.5]|\n",
      "|b  |orange|2  |1.4|0  |yes|(2,[0],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,1.0,0.0,1.0,1.4]|\n",
      "|b  |peach |2  |2.1|0  |yes|(2,[0],[1.0])|(2,[1],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,1.0,2.1]|\n",
      "|c  |peach |4  |1.5|1  |yes|(2,[],[])    |(2,[1],[1.0])|(1,[],[])    |(1,[0],[1.0])|(6,[3,5],[1.0,1.5])      |\n",
      "+---+------+---+---+---+---+-------------+-------------+-------------+-------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_assembled=VectorAssembler(inputCols=['ohe_x1','ohe_x2','ohe_y1','x4'],outputCol= 'featuresCol')\\\n",
    "            .transform(df_new)\\\n",
    "            .drop('indexed_x1','indexed_x2','indexed_y1','indexed_y2')\n",
    "df_assembled.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates, Outliers, Missing observations\n",
    "Your data can be stained with duplicates, missing observations and outliers, non-existent addresses, wrong phone numbers and area codes, inaccurate geographical coordinates, wrong dates, incorrect labels, mixtures of upper and lower cases, trailing spaces, and many other more subtle problems. It is your job to clean it, irrespective of whether you are a data scientist or data engineer, so you can build a statistical or machine learning model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "(1, 144.5, 5.9, 33, 'M'),\n",
    "(2, 167.2, 5.4, 45, 'M'),\n",
    "(3, 124.1, 5.2, 23, 'F'),\n",
    "(4, 144.5, 5.9, 33, 'M'),\n",
    "(5, 133.2, 5.7, 54, 'F'),\n",
    "(3, 124.1, 5.2, 23, 'F'),\n",
    "(5, 129.2, 5.3, 42, 'M'),\n",
    "], ['id', 'weight', 'height', 'age', 'gender'])\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.drop_duplicates()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.dropDuplicates(subset=[c for c in df.columns if c!='id'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|count|distinct|\n",
      "+-----+--------+\n",
      "|    5|       4|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "df.agg(\n",
    "        fn.count('id').alias('count'),\n",
    "        fn.countDistinct('id').alias('distinct')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+------+---+------+\n",
      "|           id|weight|height|age|gender|\n",
      "+-------------+------+------+---+------+\n",
      "|  25769803776| 133.2|   5.7| 54|     F|\n",
      "| 171798691840| 144.5|   5.9| 33|     M|\n",
      "| 592705486848| 167.2|   5.4| 45|     M|\n",
      "|1236950581248| 124.1|   5.2| 23|     F|\n",
      "|1365799600128| 129.2|   5.3| 42|     M|\n",
      "+-------------+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('id',fn.monotonically_increasing_id()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  1| 143.5|   5.6|  28|     M|100000|\n",
      "|  2| 167.2|   5.4|  45|     M|  null|\n",
      "|  3|  null|   5.2|null|  null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|  null|\n",
      "|  5| 133.2|   5.7|  54|     F|  null|\n",
      "|  6| 124.1|   5.2|null|     F|  null|\n",
      "|  7| 129.2|   5.3|  42|     M| 76000|\n",
      "+---+------+------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "df_miss = spark.createDataFrame([\n",
    "        (1, 143.5, 5.6, 28,   'M',  100000),\n",
    "        (2, 167.2, 5.4, 45,   'M',  None),\n",
    "        (3, None , 5.2, None, None, None),\n",
    "        (4, 144.5, 5.9, 33,   'M',  None),\n",
    "        (5, 133.2, 5.7, 54,   'F',  None),\n",
    "        (6, 124.1, 5.2, None, 'F',  None),\n",
    "        (7, 129.2, 5.3, 42,   'M',  76000),\n",
    "    ], ['id', 'weight', 'height', 'age', 'gender', 'income'])\n",
    "\n",
    "df_miss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  3|  null|   5.2|null|  null|  null|\n",
      "+---+------+------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss.where('id==3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (2, 1), (3, 4), (4, 1), (5, 1), (6, 2), (7, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miss.rdd.map(lambda row: (row['id'], sum([c==None for c in row]))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  1| 143.5|   5.6|  28|     M|100000|\n",
      "|  2| 167.2|   5.4|  45|     M|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|  null|\n",
      "|  5| 133.2|   5.7|  54|     F|  null|\n",
      "|  6| 124.1|   5.2|null|     F|  null|\n",
      "|  7| 129.2|   5.3|  42|     M| 76000|\n",
      "+---+------+------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss.dropna(thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+\n",
      "| id|weight|height| age|gender|\n",
      "+---+------+------+----+------+\n",
      "|  1| 143.5|   5.6|  28|     M|\n",
      "|  2| 167.2|   5.4|  45|     M|\n",
      "|  3|  null|   5.2|null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|\n",
      "|  5| 133.2|   5.7|  54|     F|\n",
      "|  6| 124.1|   5.2|null|     F|\n",
      "|  7| 129.2|   5.3|  42|     M|\n",
      "+---+------+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss_no_income=df_miss.select([c for c in df_miss.columns if c!='income'])\n",
    "df_miss_no_income.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 4.0, 'weight': 140.28333333333333, 'height': 5.471428571428571, 'age': 40.4}\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "means=df_miss_no_income.agg(*[fn.mean(c).alias(c) for c in df_miss_no_income.columns if c!='gender'])\\\n",
    "        .toPandas().to_dict('records')[0]\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 40.4,\n",
       " 'gender': 'missing',\n",
       " 'height': 5.471428571428571,\n",
       " 'id': 4.0,\n",
       " 'weight': 140.28333333333333}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means['gender']='missing'\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------+---+-------+\n",
      "| id|            weight|height|age| gender|\n",
      "+---+------------------+------+---+-------+\n",
      "|  1|             143.5|   5.6| 28|      M|\n",
      "|  2|             167.2|   5.4| 45|      M|\n",
      "|  3|140.28333333333333|   5.2| 40|missing|\n",
      "|  4|             144.5|   5.9| 33|      M|\n",
      "|  5|             133.2|   5.7| 54|      F|\n",
      "|  6|             124.1|   5.2| 40|      F|\n",
      "|  7|             129.2|   5.3| 42|      M|\n",
      "+---+------------------+------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss_no_income.fillna(means).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example data\n",
    "df_outliers = spark.createDataFrame([\n",
    "        (1, 143.5, 5.3, 28),\n",
    "        (2, 154.2, 5.5, 45),\n",
    "        (3, 342.3, 5.1, 99),\n",
    "        (4, 144.5, 5.5, 33),\n",
    "        (5, 133.2, 5.4, 54),\n",
    "        (6, 124.1, 5.1, 21),\n",
    "        (7, 129.2, 5.3, 42),\n",
    "    ], ['id', 'weight', 'height', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+\n",
      "| id|weight|height|age|\n",
      "+---+------+------+---+\n",
      "|  1| 143.5|   5.3| 28|\n",
      "|  2| 154.2|   5.5| 45|\n",
      "|  3| 342.3|   5.1| 99|\n",
      "|  4| 144.5|   5.5| 33|\n",
      "|  5| 133.2|   5.4| 54|\n",
      "|  6| 124.1|   5.1| 21|\n",
      "|  7| 129.2|   5.3| 42|\n",
      "+---+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols=['weight','age']\n",
    "bounds={}\n",
    "for col in cols:\n",
    "    quantiles=df_outliers.approxQuantile(col,[.25, .75], 0.05)\n",
    "    IQR=quantiles[1]-quantiles[0]\n",
    "    bounds[col]=[quantiles[0]-1.5*IQR, quantiles[1]+1.5*IQR]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': [-11.0, 93.0], 'weight': [91.69999999999999, 191.7]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.0, 54.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+\n",
      "| id|weight_o|age_o|\n",
      "+---+--------+-----+\n",
      "|  1|   false|false|\n",
      "|  2|   false|false|\n",
      "|  3|    true| true|\n",
      "|  4|   false|false|\n",
      "|  5|   false|false|\n",
      "|  6|   false|false|\n",
      "|  7|   false|false|\n",
      "+---+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outliers=df_outliers.select(*['id'] +\n",
    "                           [\n",
    "                               (\n",
    "                                   (df_outliers[c]<bounds[c][0]) |\n",
    "                                   (df_outliers[c]>bounds[c][1])\n",
    "                               ).alias(c+'_o') for c in cols\n",
    "                           ]\n",
    "                           )\n",
    "outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_outliers=df_outliers.join(outliers,on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+--------+-----+\n",
      "| id|weight|height|age|weight_o|age_o|\n",
      "+---+------+------+---+--------+-----+\n",
      "|  7| 129.2|   5.3| 42|   false|false|\n",
      "|  6| 124.1|   5.1| 21|   false|false|\n",
      "|  5| 133.2|   5.4| 54|   false|false|\n",
      "|  1| 143.5|   5.3| 28|   false|false|\n",
      "|  3| 342.3|   5.1| 99|    true| true|\n",
      "|  2| 154.2|   5.5| 45|   false|false|\n",
      "|  4| 144.5|   5.5| 33|   false|false|\n",
      "+---+------+------+---+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+--------+-----+\n",
      "| id|weight|height|age|weight_o|age_o|\n",
      "+---+------+------+---+--------+-----+\n",
      "|  7| 129.2|   5.3| 42|   false|false|\n",
      "|  6| 124.1|   5.1| 21|   false|false|\n",
      "|  5| 133.2|   5.4| 54|   false|false|\n",
      "|  1| 143.5|   5.3| 28|   false|false|\n",
      "|  2| 154.2|   5.5| 45|   false|false|\n",
      "|  4| 144.5|   5.5| 33|   false|false|\n",
      "+---+------+------+---+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.filter(df_outliers.age_o==0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we calculate the lower and upper cut off points for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic=spark.read.csv('kaggle-titanic-train.csv',header=True,inferSchema=True)\n",
    "titanic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.groupby('Survived').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titanic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def describe_columns(df):\n",
    "    for i in df.columns:\n",
    "        print('Column: ' + i)\n",
    "        df.select(i).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: PassengerId\n",
      "+-------+-----------------+\n",
      "|summary|      PassengerId|\n",
      "+-------+-----------------+\n",
      "|  count|              891|\n",
      "|   mean|            446.0|\n",
      "| stddev|257.3538420152301|\n",
      "|    min|                1|\n",
      "|    max|              891|\n",
      "+-------+-----------------+\n",
      "\n",
      "Column: Survived\n",
      "+-------+-------------------+\n",
      "|summary|           Survived|\n",
      "+-------+-------------------+\n",
      "|  count|                891|\n",
      "|   mean| 0.3838383838383838|\n",
      "| stddev|0.48659245426485753|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n",
      "Column: Pclass\n",
      "+-------+------------------+\n",
      "|summary|            Pclass|\n",
      "+-------+------------------+\n",
      "|  count|               891|\n",
      "|   mean| 2.308641975308642|\n",
      "| stddev|0.8360712409770491|\n",
      "|    min|                 1|\n",
      "|    max|                 3|\n",
      "+-------+------------------+\n",
      "\n",
      "Column: Name\n",
      "+-------+--------------------+\n",
      "|summary|                Name|\n",
      "+-------+--------------------+\n",
      "|  count|                 891|\n",
      "|   mean|                null|\n",
      "| stddev|                null|\n",
      "|    min|\"Andersson, Mr. A...|\n",
      "|    max|van Melkebeke, Mr...|\n",
      "+-------+--------------------+\n",
      "\n",
      "Column: Sex\n",
      "+-------+------+\n",
      "|summary|   Sex|\n",
      "+-------+------+\n",
      "|  count|   891|\n",
      "|   mean|  null|\n",
      "| stddev|  null|\n",
      "|    min|female|\n",
      "|    max|  male|\n",
      "+-------+------+\n",
      "\n",
      "Column: Age\n",
      "+-------+------------------+\n",
      "|summary|               Age|\n",
      "+-------+------------------+\n",
      "|  count|               714|\n",
      "|   mean| 29.69911764705882|\n",
      "| stddev|14.526497332334035|\n",
      "|    min|              0.42|\n",
      "|    max|              80.0|\n",
      "+-------+------------------+\n",
      "\n",
      "Column: SibSp\n",
      "+-------+------------------+\n",
      "|summary|             SibSp|\n",
      "+-------+------------------+\n",
      "|  count|               891|\n",
      "|   mean|0.5230078563411896|\n",
      "| stddev|1.1027434322934315|\n",
      "|    min|                 0|\n",
      "|    max|                 8|\n",
      "+-------+------------------+\n",
      "\n",
      "Column: Parch\n",
      "+-------+-------------------+\n",
      "|summary|              Parch|\n",
      "+-------+-------------------+\n",
      "|  count|                891|\n",
      "|   mean|0.38159371492704824|\n",
      "| stddev| 0.8060572211299488|\n",
      "|    min|                  0|\n",
      "|    max|                  6|\n",
      "+-------+-------------------+\n",
      "\n",
      "Column: Ticket\n",
      "+-------+------------------+\n",
      "|summary|            Ticket|\n",
      "+-------+------------------+\n",
      "|  count|               891|\n",
      "|   mean|260318.54916792738|\n",
      "| stddev|471609.26868834975|\n",
      "|    min|            110152|\n",
      "|    max|         WE/P 5735|\n",
      "+-------+------------------+\n",
      "\n",
      "Column: Fare\n",
      "+-------+-----------------+\n",
      "|summary|             Fare|\n",
      "+-------+-----------------+\n",
      "|  count|              891|\n",
      "|   mean| 32.2042079685746|\n",
      "| stddev|49.69342859718089|\n",
      "|    min|              0.0|\n",
      "|    max|         512.3292|\n",
      "+-------+-----------------+\n",
      "\n",
      "Column: Cabin\n",
      "+-------+-----+\n",
      "|summary|Cabin|\n",
      "+-------+-----+\n",
      "|  count|  204|\n",
      "|   mean| null|\n",
      "| stddev| null|\n",
      "|    min|  A10|\n",
      "|    max|    T|\n",
      "+-------+-----+\n",
      "\n",
      "Column: Embarked\n",
      "+-------+--------+\n",
      "|summary|Embarked|\n",
      "+-------+--------+\n",
      "|  count|     889|\n",
      "|   mean|    null|\n",
      "| stddev|    null|\n",
      "|    min|       C|\n",
      "|    max|       S|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe_columns(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate statistics\n",
    "\n",
    "To calculate a given statistics we can use function agg combined with appropriate aggregation function.  \n",
    "A list of aggregation functions (the names are fairly self-explanatory) includes:\n",
    "`avg()`, `count()`, `countDistinct()`, `first()`, `kurtosis()`, `max()`, `mean()`, `min()`,\n",
    "`skewness()`, `stddev()`, `stddev_pop()`, `stddev_samp()`, `sum()`, `sumDistinct()`,\n",
    "`var_pop()`, `var_samp()` and `variance()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|   skewness(Fare)|\n",
      "+-----------------+\n",
      "|4.779253292372357|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.agg({'Fare': 'skewness'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations\n",
    "\n",
    "Calculating correlations in PySpark is very easy once your data is in a DataFrame\n",
    "form. The only difficulties are that the `.corr(...)` method supports the Pearson\n",
    "correlation coefficient at the moment, and it can only calculate pairwise correlations,\n",
    "such as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.135515853527051"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.corr('Fare','Age')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
